# Amazon S3

## Bucket

This allows for object (files) storage in a "bucket" (directory).
There are some facts related to it:
- Buckets must have a globally unique name (across all regions and all accounts)
- Buckets are defined at the region level
- Buckets are created in a region (not global)
- Naming Convention (no uppercase, no underscore, 3-63 characters long,  must start with lowercase, must not start with prefix "xn-" or suffix "-s3alias")

## Objects

Are files which have a **key**, which represents the **full path** (e.g.: "s3://my-bucket/my_folder1/another_folder/my_file.txt"), and is compose of a **prefix** (e.g.: "my_folder1/another_folder") and the **object name** (e.g.: "my_file.txt").
**Note that are no concept of "directories" withing buckets.**

Some restrictions are in place for objects:
- Max object size is 5TB (5000GB)
- If uploading more than > 5GB => you must use "multi-part upload"

Objects are comprised of: 
- Value which is the content of the body
- Metadata (list of text key / value pairs - system or user metadata)
- Tags (Unicode key / value pair up to 10)
- Version ID (if versioning enabled)

### Versioning
You can version if it enabled at bucket level which will result in the same key overwrite to just change the version (any versioned prior to enable versioning will have version "null")

## Security

1. User-Based
  - IAM Policies - which API calls should be allowed for a specific user from IAM
2. Resource-Based
- Bucket Policies (bucket wide rules from the S3 console - allows cross account)
- Object Access Control List (ACL) - finer grain (can be disabled)
- Bucket Access Control List (ACL) - less common (can be disabled)

**Note**: an IAM principal can access an S3 object if:
- The user IAM permissions ALLOWS it or hte resource policy ALLOWS it
- **AND** there's no explicit DENY

### S3 Bucket Policies

JSON based policies
- Resources: bucket and objects
- Effect: Allow/Deny
- Actions: Set of API to Allow or Deny
- Principal: the account or user to apply the policy to

Use it for:
- Grant public access to the bucket
- Force objects to be encrypted at upload
- Grant access to another account (Cross Account)

## Replication (CRR & SRR)

It requires versioning to be enabled in source and destination buckets. It is of 2 types:
- Cross-Region Replication (CRR) (e.g.: used in compliance, lower latency access, replication accross accounts
- Same-Region Replication (SRR) (e.g.: log aggregation, live replication between production and test accounts)

Note that copying is asynchronous and you must give proper IAM permissions to S3.

## Storage Classes

**Durability** = how long objects stored are expected to incur losses on average (e.g.: High Durability: 99.999999999% => 10,000,000 boject you can expect 1 single object loss every 10,000 years). **For S3 is the same for all storage classes**.
**Availabity** = measures how readility available a service is, varies depending on storage class

### Standard Class
- S3 Standard - General Purpose 
  - 99.99% Availability
  - Used for frequently accessed data
  - Low Latency and High Throughput
  - Sustain 2 concurrent facility failures
  - Use Cases: Big Data analytics, mobile & gaming applications, content distribution

### Infrequent Access Class
For data that is less frequently accessed but requires rapid access when needed.

- S3 Standard-Infrequent Access (IA)
  - 99.9 availability
  - Use Cases: Disaster recovery, backups
  - Lower Cost than General purpose
- S3 One Zone-Infrequent Access
  - High durability (99.999999999%) in a single AZ, data lost when AZ is destroyed
  - 99.5% Availability
  - Use Cases: Storing secondary backup copises of on-premise data or data you can recreate
  - Lower Cost than Standard-Infrequent Access

### Glacier Storage Class
Low-cost object storage meant for archiving /backup. The pricing is based on price for storage + object retrieval cost.

- S3 Glacier Instant Retrieval
  - milisecond retrieval, great for data accessed once a quarter
  - Minimum storage duration of 90 days
  - Lower Cost than One Zone-Infrequent Access
- S3 Glacier Flexible Retrieval
  - Expedited (1 to 5 minutes), Standard (3 to 5 hours), Bulk (5 to 12 hours) - free
  - Minimum storage duration of 90 days
  - Lower Cost than S3 Glacier Instant Retrieval
- S3 Glacier Deep Archive
  - Standard (12 hours), Bulk (48 hours)
  - Minimum storage duration of 180 days
  - Lower Cost than S3 Glacier Flexible Retrieval

### Inteligent Class
- S3 Inteligent Tiering
  - Small monthly monitoring and auto-tiering fee
  - Move access between access tiers based on usage
  - No retrieval charges

## Shared Responsability Model for S3

AWS | You (client)
|---|---|
Infrastructure | S3 versioning
Configuration and vulnerability analysis | S3 Bucket Policies
Compliance Validation | S3 Replication Setup
|| Logging and Monitoring
|| S3 Storage Classes
|| Data encryption at rest and in transit


## Snow Family 

Highly-secure, portable devices to collect and process data at the edge (limited / no internet access or computing power) and migrate data into and out of AWS. Note if it takes more than a week to transfer over the network => use Snowball devices. All of them can run EC2 Instances & AWS lambda functions (using IoT Greengrass)

Data Migration | Edge Computing
|---|---|
Snowcone | Snowcone
Snowball Edge | Snowball Edge
Snowmobile | 

1. Snowball Edge
- Physical data transport solution
- Pay per data transfer job
- Provide block storage and Amazon S3-compatible object storage
- It can Storage Optimized (80TB HDD, 40vCPU, 80GiB RAM) or Compute Optimized (42TB HDD, 52vCPU, 208 GiB Ram)
2. Snowcone
- Portable computing
- 8 TB of usable storage
- Smaller device (use Snowcone where Snowball does not fit)
- Can also be synced using **AWS DataSync** over the internet (alternative to offline option)
3. Snowmobile
- A very large truck to transfer exabytes of data
- High security, temperature controlled
- Use if you transfer more than 10 PB

### Aws OpsHub = used to manage Snow Family Devices (transfering files, configuring devices, launching/managing instance s running on devices)

## AWS Storage Gateway 

- Bridge between on-premise data and cloud data in S3, Hybrid storage service to allow on-premises to seamlessly use the AWS cloud.
- Use Cases: disaster recovery, backup & restore, tiered storage
- Has 3 Types:
  - Tape Gateway
  - File Gateway
  - Volume Gateway

